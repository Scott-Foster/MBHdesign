stroi()
?strtoi
stroi("A380")
base::stroi("A380")
strtoi(c("ffff", "FFFF"), 16L)
base::strtoi("A380")
base::strtoi("Ax380")
base::strtoi("380")
base::strtoi("A")
base::strtoi("a")
base::strtoi("f")
base::strtoi("ffff")
strtoi(c("ffff", "FFFF"), 16L)
strtoi(c("177", "377"), 8L)
strtoi(c("177", "A380"), 8L)
set.seed( 767)
#the number of potential sampling locations
N <- 50^2
#number of samples
n <- 10
#the grid on unit square
X <- as.matrix( expand.grid( 1:sqrt( N), 1:sqrt(N)) / sqrt(N) - 1/(2*sqrt(N)))
#the inclusion probabiltiies with gradient according to non-linear function of X[,1]
p <- 1-exp(-X[,1])
#standardise to get n samples
p <- n * p / sum( p)
#get the sample
#note that 5 points on the transect line and 5 directions considered is probably cutting things a bit thin.
#This low-definition is done to avoid trouble with CRAN's checks (no example should take a long time to run).
samp <- transectSamp( n, potential.sites=X, inclusion.probs=p, control=list( transect.patter="line", nRotate=5, transect.nPts=5))
plot( samp$points[,5:6], main="n=10 TRANSECTS")
#tidy
rm( N, n, X, p, samp)
mtrace.off()
lso()
rm( allCumProbs, allPerms, alpha, approx1, df, doDeleteThis, ii, m ,M maxes, maxxy, minny, myPatter, nPts.per.side, plot, potential.sites, ret, survey.area, test, tester2, transect_probs, x, y)
rm( allCumProbs, allPerms, alpha, approx1, df, doDeleteThis, ii, m ,M, maxes, maxxy, minny, myPatter, nPts.per.side, plot, potential.sites, ret, survey.area, test, tester2, transect_probs, x, y)
lso()
rm( adjustEdge, adjustEdge1, adjustEdge2, alterInclProbs, alterInclProbs_transect, alterInclProbs_transect2, BAS_samp_for1, calcExactInclusionProbs2, degrees2radians, find.sigma, find.sigma_transect, funny.cell, funnyfunny1, funny.transect, getCandidateSet, getControl, getGAMpred, getGridInHull, getProbs, getProbs2, getSingleSiteLocProbs, getSingleTransLocProbs, getTransect, modEsti, prodOnLog, ptDist, quasiSamp, quasiSamp_transect, rescaleProbs, rescaleProbs2, setDesignParams, setDesignParams_transect, set.transect.control, setTransectParams, transectSamp)
lso()
rm( clean.tcl, lso)
ls
lso()
ls()
rm( myPattern, tester)
ls()
source('~/NESP/MonitoringTheme/SOPproject/MBHdesign/MBHdesign/R/MBHdesign.R')
source('~/NESP/MonitoringTheme/SOPproject/MBHdesign/MBHdesign/R/FunsForTransect3.R')
library(MBHdesign)
library( knitr)
.libPaths()
install.packages( knitr, lib="~/lib/R/library")
install.packages( "knitr", lib="~/lib/R/library")
install.packages( "spsurvey", lib="~/lib/R/library")
?packageStartupMessage
foodweb()
library( mvbutils)
foodweb()
foodweb()
lso
lso()
rm( clean.tcl, lso)
lso()
ls()
.onLoad
ls(all=TRUE)
.First
ls()
.onLoad()
source('~/NESP/MonitoringTheme/SOPproject/MBHdesign/MBHdesign/R/onLoad.R')
.onLoad()
?packageStartupMessage
library(MBHdesign)
sessionInfo()
mtrace( transectSamp)
mtrace( alterInclProbs_transect2)
transectSamp( 5)
mtrace( setDesignParams_transect)
N
dimension1=1:N$dimension1 / N$dimension1 - 1/(2*N$dimension1)
dimension2=1:N$dimension2 / N$dimension2 - 1/(2*N$dimension2)
direction=seq( from=0, to=360-360/N$rotate, length=N$rotate)
N
qqq()
source('~/NESP/MonitoringTheme/SOPproject/MBHdesign/MBHdesign/R/FunsForTransect3.R')
transectSamp( 5)
qqq()
source('~/NESP/MonitoringTheme/SOPproject/MBHdesign/MBHdesign/R/FunsForTransect3.R')
transectSamp( 5)
control$N
mtrace( setDesignParams_transect)
N
qqq()
source('~/NESP/MonitoringTheme/SOPproject/MBHdesign/MBHdesign/R/FunsForTransect3.R')
transectSamp( 5)
control$doPlot <- TRUE
skip( 10)
library( fields)
mtrace( alterInclProbs_transect2)
chosenTransects[[ii]]
mtrace( alterInclProbs_transect2, F)
?quasiSamp
set.seed(707)
#the number of potential sampling locations
N <- 100^2
#number of transects
n <- 10
#the grid on unit square
X <- as.matrix( expand.grid( 1:sqrt( N), 1:sqrt(N)) / sqrt(N) - 1/(2*sqrt(N)))
#the inclusion probabiltiies with gradient according to non-linear function of X[,1]
p <- 1-exp(-X[,1])
#standardise to get n samples
p <- n * p / sum( p)
rm( N, n, X, p)
lso()
rm( lso, clean.tcl)
library(MBHdesign)
?geometry::convhulln
cite( geometry)
cite( "geometry")
cite( "geometry::convhulln")
citation( "geometry")
source('~/NESP/MonitoringTheme/SOPproject/MBHdesign/MBHdesign/R/FunsForTransect3.R')
source('~/NESP/MonitoringTheme/SOPproject/MBHdesign/MBHdesign/R/FunsForTransect3.R')
source('~/NESP/MonitoringTheme/SOPproject/MBHdesign/MBHdesign/R/FunsForTransect3.R')
q()
q()
library( MBHdesign)
lso()
q()
q()
q()
library(MBHdesign)
uninstall.packages( "MBHdesign")
remove.packages( "MBHdesign")
remove.packages( "MBHdesign")
library(MBHdesign)
library(MBHdesign, lib="~/lib/R/library")
remove.packages(MBHdesign, lib="~/lib/R/library")
remove.packages( "MBHdesign", lib="~/lib/R/library")
remove.packages( "MBHdesign")
library(MBHdesign)
remove.packages( "MBHdesign")
remove.packages( "MBHdesign", lib="~/lib/R/library")
remove.packages( "MBHdesign", lib="~/lib/R/library")
remove.packages( "MBHdesign")
remove.packages( "MBHdesign", lib="~/lib/R/library")
library( MBHdesign, lib="~/lib/R/library")
remove.packages( "MBHdesign")
remove.packages( "MBHdesign", lib="~/lib/R/library")
source('~/NESP/MonitoringTheme/SOPproject/MBHdesign/MBHdesign/R/FunsForTransect3.R')
100*100
100*100 * 0.05
detach( package:MBHdesign)
detach( 'package:MBHdesign')
detach( "package:MBHdesign")
library( MBHdesign)
detach( "package:MBHdesign")
library( MBHdesign)
detach( "package:MBHdesign")
args( apply)
detach( package:MBHdesign)
detach( package:MBHdesign)
lso()
#find the observed inclusion probabilities
obsProbs <- parallel::parLapply(cl, 1:designParams$N$Tot.xy, obsCellProb2, locProbs.raw=locProbs.raw, toc.list=tranOverCell.list)
source('~/NESP/MonitoringTheme/SOPproject/MBHdesign/MBHdesign/R/FunsForTransect4_play.R')
source('~/NESP/MonitoringTheme/SOPproject/MBHdesign/MBHdesign/R/FunsForTransect4_play.R')
54/60
54/60 + 3
5*( 54/60 + 3)
5*( 45/60 + 3)
args( class:knn1)
args( class::knn1)
library( glmnet)
?glmnet
?glmnet::coef.glmnet
args( quasiSamp)
args( sample)
?quasiSamp
?center
?centre
?scale
rep( 1:3, 5)
rep( 1:3, each=5)
expand.grid( matrix( 1:6, ncol=2), 1:3)
?quasiSamp
360 / 10
seq( from=0, to=360, by=10)
(3+4/6)
(3+4/6) * 5
(3+35/60) * 5
mat <- matrix( c( 1,2,3,4, 7,5,6,8), ncol=4, nrow=2, byrow=TRUE)
layout( may)
mat <- matrix( c( 1,2,3,4, 7,5,6,8), ncol=4, nrow=2, byrow=TRUE)
layout( mat)
show.layout
?layout.show(8)
?layout.show(8)
layout.show(8)
?layout
mat <- matrix( c( 1,2,3,4, 7,5,6,8), ncol=4, nrow=2, byrow=TRUE)
layout( mat, widths=c(1,1,1,0.3))
layout.show(8)
mat <- matrix( c( 0,0,0,0, 1,2,3,4, 7,5,6,8)+1, ncol=4, nrow=2, byrow=TRUE)
layout( mat, widths=c(1,1,1,0.3))
layout.show(9)
mat <- matrix( c( 0,0,0,0, 1,2,3,4, 7,5,6,8)+1, ncol=4, nrow=3, byrow=TRUE)
layout( mat, widths=c(1,1,1,0.3))
layout.show(9)
mat <- matrix( c( 0,0,0,0, 1,2,3,4, 7,5,6,8)+1, ncol=4, nrow=3, byrow=TRUE)
layout( mat, widths=c(1,1,1,0.3), heights=c(1,4,4))
layout.show(9)
args( sample)
args( mgcv:::in.out)
?mgcv:::in.out
?quasiSamp
?setdiff
setdiff(1:5, 3)
setdiff(3, 1:5)
2^5
3^5
combination( 8000, 5)
?stop
lso()
rm( adjustEdge2, adjustEdge3, adjustEdge4, alterinclProbs, alterInclProbs_transect2, calcExactInclusionProbs2, degrees2radians, find.sigma, find.sigma_transect, getControl, getGAMpred, getGridInHull, getIDs, getProbs2, getSingleSiteLocProbs, getSingleTransLocProbs, getTransect, modEsti, obsCellProb, obsCellProb2, quasiSamp, rescaleProbs2, setDesignParams, setDesignParams_transect, set.transect.control, setTransectParams, transectSamp, transectOverCells)
lso()
rm( mat, alterInclProbs, transectsOverCells)
lso()
130*52
1425*16.6
1425*0.166
?example
tools::showNonASCIIfile("transectSamp.Rd")
dir()
tools::showNonASCIIfile("./man/transectSamp.Rd")
tools::showNonASCIIfile("./man/transectSamp.Rd")
tools::showNonASCIIfile("./man/alterInclProbs.Rd")
?Rd2pdf
getwd()
?message
diff( 0, NA)
diff(0,1)
diff(c(0,1))
diff(c(0,NA))
unique( NA, 0, 1)
unique( NA, 0, 1)
all( c(0,1,1,1,0) %in% c(0,1))
all( c(0,1,1,1,0) %in% c(0,-1))
all( c(0,1,1,NA,0) %in% c(0,-1))
all( c(0,1,1,NA,0) %in% c(0,1))
all( c(0,1,1,NA,0) %in% c(0,1, NA))
is.null( TURE)
is.null( TRUE)
is.null( NULL)
NaN
NaN %in% c( NA, NaN)
NaN %in% c( NA, "NaN")
NaN %in% c( NA, "NaN")
na.exlude( c( 1,2,3,NA,NaN))
na.remove( c( 1,2,3,NA,NaN))
na.omit( c( 1,2,3,NA,NaN))
?ifelse
?quasiSamp
lso()
21.1 * (4+10/60)
(21.1 * (4+10/60)) / 60
0.46*60
(21.1 * (4+5/60)) / 60
0.435972*60
(21.1*2 * (4+20/60)) / 60
0.047778*60
(21.1*2 * (4+15/60)) / 60
foodweb()
library( mvbutils)
?foodweb
foodweb()
?message
getwd()
lso()
install.packages( "knitr", lib="~/lib/R/library")
install.packages( "geometry", lib="~/lib/R/library")
install.packages( "randToolBox", lib="~/lib/R/library")
install.packages( "randtoolbox", lib="~/lib/R/library")
install.packages( "mvtnorm", lib="~/lib/R/library")
install.packages( "spsurvey", lib="~/lib/R/library")
install.packages( "rgeos", lib="~/lib/R/library")
install.packages( "rgeos", lib="~/lib/R/library")
install.packages( "spsurvey", lib="~/lib/R/library")
citation(MASS)
citation("MASS")
?repos
options()
options()$repos
lso()
r <- getOption("repos")
r["CRAN"] <- "https://cran.ms.unimelb.edu.au"
r <- unique( c( mvb='https://markbravington.github.com/Rmvb-repo', r))
options(repos = r)
!require( debug)
install.packages( debug, lib="~/lib/R/library")
install.packages( "debug", lib="~/lib/R/library")
sessionInfo()
require( debug)
.libPaths()
.libPaths(c("/home/fos085/lib/R/library",.libPaths()))
#set the repos
r <- getOption("repos")
r
r["CRAN"] <- "https://cran.ms.unimelb.edu.au"
r <- unique( c( mvb='https://markbravington.github.com/Rmvb-repo', r))
options(repos = r)
install.packages( "debug", lib="~/lib/R/library")
install.packages( pkg=debug, lib="~/lib/R/library")
install.packages( "debug", lib="~/lib/R/library")
options(warn = 1)
options(download.file.method = "wget")
library( statquotes)
print( statquote())
library( randquotes)
cat("\n",randquotes::randquote_simple(),"\n\n")
if( !require( statquotes)){
install.packages( "statquotes", lib="~/lib/R/library")
library( statquotes)
}
print( statquote())
if( !require( randquotes)){
install.packages( "randquotes", lib="~/lib/R/library")
library( randquotes)
}
cat("\n",randquotes::randquote_simple(),"\n\n")
install.packages( "xml2", lib="~/lib/R/library")
install.packages( "xml2", lib="~/lib/R/library")
if( !require( statquotes)){
install.packages( "statquotes", lib="~/lib/R/library")
library( statquotes)
}
print( statquote())
if( !require( randquotes)){
install.packages( "randquotes", lib="~/lib/R/library")
library( randquotes)
}
cat("\n",randquotes::randquote_simple(),"\n\n")
source('~/.Rprofile')
.First()
lso()
r
rm( r)
source('~/.Rprofile')
.First()
?transectSamp
lso()
library( parallel)
?clusterSetRNGStream
library( MBHdesign)
vignette( MBHdesign)
vignette( "MBHdesign")
fix( quasiSamp)
?transectSamp
rm( quasiSamp)
devtools::build_vignettes(pkg=".")
devtools::build( pkg=".", vignettes=FALSE)
devtools::install_github( repo="Scott-Foster/MBHdesign", build_vignettes=FALSE)
devtools::install_github( repo="Scott-Foster/MBHdesign", build_vignettes=FALSE, force=TRUE)
library( MBHdesign)
vignette( "MBHdesign")
rm( quasiSamp)
q()
devtools::build_vignettes(pkg=".")
?tools::compactPDF
?devtools::build_vignettes
getwd()
?files
dir( "./doc/")
dir( "./doc/*.pdf")
dir( "./doc/")
grep( ".pdf", dir( "./doc/"))
dir( "./doc/")[grep( ".pdf", dir( "./doc/"))]
tools::compactPDF(dir( "./doc/")[grep( ".pdf", dir( "./doc/"))], gs_quality = "ebook")
?compactPDF
tools::compactPDF(dir( "./doc/",full.names = TRUE)[grep( ".pdf", dir( "./doc/"))], gs_quality = "ebook")
dir( "./doc/",full.names = TRUE)[grep( ".pdf", dir( "./doc/"))]
tools::compactPDF(dir( "./doc", full.names=TRUE)[grep( ".pdf", dir( "./doc/"))], gs_quality = "ebook")
dir( "./doc", full.names=TRUE)[grep( ".pdf", dir( "./doc/"))]
devtools::build( pkg=".", vignettes=FALSE)
q()
devtools::build_vignettes(pkg=".")
tools::compactPDF(dir( "./doc", full.names=TRUE)[grep( ".pdf", dir( "./doc/"))], gs_quality = "ebook")
devtools::build_vignettes(pkg=".")
tools::compactPDF(dir( "./doc", full.names=TRUE)[grep( ".pdf", dir( "./doc/"))], gs_quality = "ebook")
devtools::build( pkg=".", vignettes=FALSE)
devtools::build( pkg=".", vignettes=FALSE)
devtools::build_vignettes(pkg=".")
tools::compactPDF(dir( "./doc", full.names=TRUE)[grep( ".pdf", dir( "./doc/"))], gs_quality = "ebook")
source( "mv doc ./inst")
getwd()
dir()
source( "mv doc inst")
source( "mv -f doc/ inst/")
source( "mv -f ./doc/ ./inst/")
dir
dir()
?source
?system
system( "mv -f ./doc/ ./inst/")
devtools::build( pkg=".", vignettes=FALSE)
devtools::build( pkg=".", vignettes=FALSE)
?devtools::install_github
devtools::install_github("Scott-Foster/MBHdesign", library="~/lib/R/library", upgrade="ask")
q()
devtools::build_vignettes(pkg=".")
tools::compactPDF(dir( "./doc", full.names=TRUE)[grep( ".pdf", dir( "./doc/"))], gs_quality = "ebook")
system( "mv -f ./doc/ ./inst/")
devtools::build( pkg=".", vignettes=FALSE)	#for uploading to github (but why would you?)
devtools::build_vignettes(pkg=".")
.Last.error
Sweave( "MBHdesign.rnw")
Sweave( "./vignettes/MBHdesign.rnw")
Sweave( "./vignettes/MBHdesign.rnw")
library( MBHdesign)
#need raster functions
library( raster)
#I'm currently on a Embraer 190, so it *almost* seems appropriate
set.seed( 747)
#import the data and flip it so that latitudes index south to north
volcano <- datasets::volcano[nrow(datasets::volcano):1,]
#re-align the minimum altitude
volcano <- volcano - min( volcano)
#exaggerate altitude
volcano <- 50*volcano
#rescale for inclusion probabilities
#10 clusters of 5 sites
volcano <- 10*5*volcano / sum( volcano)
#cast to a raster
volcano <- raster( volcano, crs="+proj=utm +datum=WGS84 +units=km")
#take the cluster sample
#increase mc.cores for faster processing
#samp <- quasiSamp.cluster( nCluster=10, clusterSize=5, clusterRadius=0.05,
#				inclusion.probs = volcano, mc.cores=1)
#plot it over the volcano data
plot( volcano)
#take the cluster sample
#increase mc.cores for faster processing
samp <- quasiSamp.cluster( nCluster=10, clusterSize=5, clusterRadius=0.05,
inclusion.probs = volcano, mc.cores=1)
options()$warn
options()$error
options()$warn <-2
options(warn=2)
#take the cluster sample
#increase mc.cores for faster processing
samp <- quasiSamp.cluster( nCluster=10, clusterSize=5, clusterRadius=0.05,
inclusion.probs = volcano, mc.cores=1)
mtrace( quasiSamp.cluster)
#take the cluster sample
#increase mc.cores for faster processing
samp <- quasiSamp.cluster( nCluster=10, clusterSize=5, clusterRadius=0.05,
inclusion.probs = volcano, mc.cores=1)
mtrace( alterInclProbs.cluster)
#take the cluster sample
#increase mc.cores for faster processing
samp <- quasiSamp.cluster( nCluster=10, clusterSize=5, clusterRadius=0.05,
inclusion.probs = volcano, mc.cores=1)
qqq()
#take the cluster sample
#increase mc.cores for faster processing
samp <- quasiSamp.cluster( nCluster=10, clusterSize=5, clusterRadius=0.05,
inclusion.probs = volcano, mc.cores=1)
go()
go()
mtrace.off()
#take the cluster sample
#increase mc.cores for faster processing
samp <- quasiSamp.cluster( nCluster=10, clusterSize=5, clusterRadius=0.05,
inclusion.probs = volcano, mc.cores=1)
#plot it over the volcano data
plot( volcano)
#the sample points
plot( samp, add=TRUE)
#the centres of the clusters
#		(not sample points but potentially useful nevertheless)
plot( attr( samp, "clusterDes"), add=TRUE, pch=1, col='red')
#need raster functions
library( raster)
#I'm currently on a Embraer 190, so it *almost* seems appropriate
set.seed( 747)
#import the data and flip it so that latitudes index south to north
volcano <- datasets::volcano[nrow(datasets::volcano):1,]
#re-align the minimum altitude
volcano <- volcano - min( volcano)
#exaggerate altitude
volcano <- 50*volcano
#rescale for inclusion probabilities
#10 clusters of 5 sites
volcano <- 10*5*volcano / sum( volcano)
#cast to a raster
volcano <- raster( volcano, crs="+proj=utm +datum=WGS84 +units=km")
volcano
plot( volcano)
mtrace( quasiSamp.cluster)
library( MBHdesign)
mtrace( quasiSamp.cluster)
#take the cluster sample
#increase mc.cores for faster processing
samp <- quasiSamp.cluster( nCluster=10, clusterSize=5, clusterRadius=0.05,
inclusion.probs = volcano, mc.cores=1)
mtrace( quasiSamp.raster)
class( inclusion.probs)
qqq()
mtrace.off()
exit
q()
